ТЕХНИЧЕСКОЕ ЗАДАНИЕ


Наименование, основание и сроки выполнения Проекта


1.1.	Наименование: «Разработка Нейронных систем локализации».


1.2.	Срок выполнения:


1.2.1.	Начало: с даты подписания договора (T);
1.2.2.	Окончание: T+11 месяцев.


2. Описание проекта
1. Система смартфон-сервер
Смартфон: Автономная система локализации смартфона требует следующего списка спецификаций, который отличает картографию от локализации:
a) Условия записи картографических данных будут проводиться в максимально статичных условиях, прося людей не появляться и описывая траекторию над областью записи с помощью записывающей платформы (подробнее ниже).
b) Условиями тестирования для локализации будет ручной смартфон при ходьбе, подобной человеческой, ориентация ограничена видом вперед, с низкой динамикой, стабильным захватом устройства (это эквивалентно низкому размытию) и указанием на текстурированные области, когда это возможно (области без текстуры, такие как узкий вид на плоскую стену, конечно, дадут плохое решение).
c) Сцены будут ограничены двумя сценами и следующими характеристиками:
среда, похожая на кампус, и здание.
-Площадь не будет превышать 2000 м2
-Запись будет осуществляться командой Сколтех.
-Условия освещения будут одинаковыми для разных сцен.
-Для локализации будет контролироваться динамика сцены: некоторое количество людей будет разрешено, но большое количество людей (>20 на изображении) приведет к тому, что система локализации, скорее всего, не сработает.
- В раздел документации (1.9) будет включено руководство по созданию и обработке новой сцены.
d) Решение для локализации будет представлять собой 3D-позу, которая позже будет спроецирована в 2D-пространство для визуализации приложения.

Мобильное устройство локализации: смартфон Samsung s20 (или другие эквивалентные доступные смартфоны высокого класса по предложению Navigine), работающий на автономном решении локализации со встроенными датчиками.
Картографическая платформа: требует записи данных с мобильного телефона, включая RGB видео со смартфона плюс камера глубины Azure Kinect DK. Эта сеть датчиков требует синхронизации времени через микроконтроллер (MCU). См. рисунок 1.




Рис. 1. Записывающая платформа, объединяющая смартфон и камеру глубины Azure kinect. 
Сервер: высокопроизводительный сервер с возможностями обработки на GPU.
Нейросетевой фреймворк: Мы начнем разработку алгоритмов на pytorch, поскольку это наиболее естественный для нас нейросетевой фреймворк, в частности PytorchLive (с использованием pytorch Mobile). Можно рассмотреть и другие альтернативы, например, Tensorflow Lite для мобильных приложений, если спецификации не будут соблюдены.
Решение, которое мы предполагаем предоставить для системы локализации, включает следующие компоненты:
1) Бортовой доступ смартфона к API датчиков низкого уровня и приложение-песочница для решения проблемы сбора данных, в основном изображений из видеопотока и измерений IMU, подготовка к интеграции алгоритма (1.4). Временные метки должны быть из одного и того же центра синхронизации. Требования включают тестирование и настройку для различных параметров, таких как частота кадров, с которой нужно получать данные, частота IMU и их интеграция, разрешение изображения, время экспозиции. Спецификации в разделе 3, рабочий план
2) Подготовка картографических данных. С платформы датчиков получите все доступные данные с датчиков: IMU, камера плюс камера глубины. Мы выберем наилучшие конфигурации датчиков и параметров и используем их для получения наилучшего результата при сборе данных для составления карты.
3) Расчет карты. После получения данных в пункте 1.2 Плана работ, мы рассчитаем решение карты, которое использует визуальную технику SLAM: стерео ORB-SLAM.
4) Решение локализации с помощью нейронного подхода, представляющего собой смесь искусственного интеллекта для извлечения и сопоставления признаков и оптимизации для оценки состояния позы камеры. Начальное относительное предположение для локализации берется из интеграции IMU. Эта реализация будет выполнена на языке pytorch в качестве первой попытки, а затем оптимизирована для мобильных приложений.
4.a)Первая итерация, запущенная на сервере на низкой частоте (менее 1 Гц).
4.b)Вторая итерация, выполняемая на борту после оптимизации сети до возможностей устройства. Мы будем исследовать компромисс между точностью и вычислительными ресурсами.
4.c) Третья итерация, нам нужно быстрое относительное позиционирование относительно медленной локализации, для этого мы будем использовать интеграцию IMU, работающих на более высокой частоте, чем 4.2. Это решение можно начать с решения по качанию от Navigine.
5) Мера доверия к качеству локализации, чтобы подать сигнал на серверную сторону, когда требуется более сложное решение.
6) Приложение для смартфонов, использующее сбор данных и их интеграцию с предоставленным алгоритмом (Navigine) Визуализации будут в 2D, спроецированные из решения 3D локализации.
Сервер-смартфон
7) Если локализация не удается на устройстве (мера доверия, описанная выше), сервер запускает "Глобальную локализацию", используя извлеченные характеристики для распознавания места по последовательности прошлых изображений плюс другие доступные датчики на фоне полномасштабной карты.

9) Документация, включая отчет, руководства для пользователей и разработчиков, код и дальнейшие инструкции, использованные в проекте.


2. Система серверов на открытом воздухе
Записывающее устройство IPNV обеспечит автономное решение проблемы локализации с помощью бортовых датчиков.
Описание платформы IPNV
Предлагаемое устройство локализации представляет собой колесного робота среднего масштаба с ограниченными вычислительными возможностями и предполагаемой автономностью для передвижения в среде, похожей на городскую. Мы усовершенствуем конструкцию в соответствии с потребностями проекта и по завершении проекта передадим один из прототипов заказчику для тестирования во второй среде.



Рис. 2. Робот Akula: платформа для картографирования и локализации.
При локализации на открытом воздухе устройства отображения и локализации одинаковы.
Список аппаратных компонентов:
- Колесная роботизированная платформа на полозьях с 2 щеточными двигателями постоянного тока.
- Модель NUC10i7 в качестве вычислительного блока и центрального процессора.
- Velodyne-16 (VLP16), 3D LiDAR сенсор
- Цветная камера Basler с широкоугольными линзами.
- Управление двигателем с помощью STM32 MCU, включая измерения одометрии с колесных энкодеров.
- Управление внешними командами с помощью пользовательского приложения UDP для джойпада смартфона.
- Любое внешнее устройство может быть интегрировано в систему (радиомаяки, BLE/Wi-Fi и т.д.) к любому из доступных разъемов питания: 5 В, 12 В, 19 В и 24 В.
- Сетевые требования: подключение по Wi-Fi к базовой станции.

Требования, в которых будет происходить локализация на открытом воздухе, должны соответствовать следующим требованиям:
- Запись данных и локализация будут происходить на мобильной платформе Akula (см. выше), движущейся со скоростью платформы (около 1 м/с) в хороших погодных условиях.
- Среда тестирования будет представлять собой ограниченную территорию в городской среде. Мы выбрали два места: 1) окрестности нового кампуса Сколтеха и 2) район Черепановых в Москве.
- Условия для картирования потребуют минимального количества людей, в то время как некоторое количество будет допустимо.
- Условия локализации будут допускать некоторое количество людей и динамических объектов относительно карты. Значительное количество людей, окружающих робота и закрывающих датчики лидара и камеры, приведет к отказу системы в локализации.
Решение по локализации
Предлагаемое решение имеет следующие требования и ожидаемые результаты:
1) Установка аппаратного обеспечения. Сборка мобильной платформы со всеми элементами управления, драйверами и бортовыми датчиками: LiDAR, камера, Wi-Fi. Требуется взаимодействие с другими партнерами в случае использования радиочастотного позиционирования.
2) Сбор картографических данных. Мы получим карту двух сцен с помощью робота Akula со всеми датчиками. Эта задача включает в себя сбор данных и правильную конфигурацию созданных картографических данных, иначе локализация не будет работать должным образом, поэтому она является деликатной задачей и требует значительного количества времени.
3) Расчет карты. Предварительно записанные данные (2.2) с использованием камер, LiDAR и радиочастотных сигналов. Это требует слияния датчиков и правильного представления карты для последующей локализации.
4) Локализация на борту робота, выполнение задачи локализации, для которой необходимо объединить информацию от различных датчиков: Лидар, IMU, одометрия колес, радио и GNSS. Мы будем исследовать оптимальный набор данных для использования. В принципе, интеграция IMU и положение радиочастоты обеспечивают грубую начальную оценку, а LiDAR и камера корректируют локализацию, обеспечивая более точную оценку. Предлагается использовать подход, аналогичный тому, что применяется в задаче со смартфоном, по возможности используя pythorch в качестве языка по умолчанию. Целевое приложение должно иметь низкие вычислительные требования, достаточные для запуска на устройствах, описанных выше.
4.a) Решение по локализации на частоте ниже 1 Гц с использованием данных Lidar плюс начальная оценка от интеграции IMU и радиочастотного позиционирования.
4.c) Одометрия/IMU для решения локализации с более высокой частотой, обеспечивая решение с более высокой частотой между оценками локализации.
5) Анализ возможностей передачи данных. Устройство отправляет поток изображений и облако точек на сервер, мы будем исследовать оптимальные условия пропускной способности и частоты кадров.
6) Глобальная локализация для случаев, когда система дает сбой. Она будет выполняться на стороне сервера, чтобы рассмотреть прошлую последовательность данных и обеспечить исправление текущей локализации.
7) Визуализация решения по локализации на стороне сервера.
8) Роботизированная платформа будет передана клиенту после модернизации необходимых деталей и завершения проекта. Эта задача включает в себя все модификации, обновления и калибровку, необходимые для демонстрации локализации на открытом воздухе, с необходимой отладкой и тестированием.
9) Документация, включая отчет, руководства и обучение для пользователей и разработчиков, код и дальнейшие инструкции, использованные в проекте  для создания новой сцены.


3. Work Plan  / План работ 


сделать визуальное представление плана работ

добавить обоснование 